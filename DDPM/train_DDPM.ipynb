{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T10:20:04.285713Z","iopub.status.busy":"2023-12-23T10:20:04.285379Z","iopub.status.idle":"2023-12-23T10:20:11.051035Z","shell.execute_reply":"2023-12-23T10:20:11.049845Z","shell.execute_reply.started":"2023-12-23T10:20:04.285664Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Subset\n","from torch.optim import AdamW\n","from torchvision import datasets, transforms\n","import torchvision.utils as vutils\n","from torch.utils.data import ConcatDataset\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline\n","from diffusers.optimization import get_cosine_schedule_with_warmup\n","from accelerate import Accelerator\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import numpy as np\n","import random \n","import timeit\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T10:20:11.053969Z","iopub.status.busy":"2023-12-23T10:20:11.053210Z","iopub.status.idle":"2023-12-23T10:20:11.089225Z","shell.execute_reply":"2023-12-23T10:20:11.088494Z","shell.execute_reply.started":"2023-12-23T10:20:11.053920Z"},"trusted":true},"outputs":[],"source":["# Configuration\n","RANDOM_SEED = 42\n","IMG_SIZE = 64 \n","BATCH_SIZE = 4\n","LEARNING_RATE = 1e-4\n","NUM_EPOCHS = 1\n","NUM_GENERATE_IMAGES = 9\n","NUM_TIMESTEPS = 1000\n","MIXED_PRECISION = \"fp16\"\n","GRADIENT_ACCUMULATION_STEPS = 1\n","\n","# Set seeds for reproducibility\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed_all(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Device configuration\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.cuda.empty_cache()\n","PATH = '../data-students/TRAIN'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T10:20:18.186832Z","iopub.status.busy":"2023-12-23T10:20:18.186568Z","iopub.status.idle":"2023-12-23T10:20:18.195847Z","shell.execute_reply":"2023-12-23T10:20:18.195087Z","shell.execute_reply.started":"2023-12-23T10:20:18.186808Z"},"trusted":true},"outputs":[],"source":["# Define Albumentations transforms\n","albumentations_transform = A.Compose([\n","    A.Rotate(limit=15, border_mode=cv2.BORDER_REFLECT, p=1.0),\n","    A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0),\n","    A.Perspective(scale=(0.05, 0.1), keep_size=True, pad_mode=cv2.BORDER_REFLECT, p=1.0),\n","    ToTensorV2()\n","])\n","\n","# Define torchvision transforms\n","torchvision_transform = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Combined transform class\n","class CombinedTransform:\n","    def __init__(self, albumentations_transform, torchvision_transform):\n","        self.albumentations_transform = albumentations_transform\n","        self.torchvision_transform = torchvision_transform\n","\n","    def __call__(self, image):\n","        # Apply Albumentations transforms\n","        image = np.array(image)\n","        augmented = self.albumentations_transform(image=image)\n","        image = augmented['image']\n","\n","        # Convert tensor to PIL Image for torchvision transforms\n","        image = transforms.ToPILImage()(image)\n","\n","        # Apply torchvision transforms\n","        image = self.torchvision_transform(image)\n","        return image\n","\n","# Use the combined transformation\n","combined_transform = CombinedTransform(albumentations_transform, torchvision_transform)\n","\n","# Initial dataset for class identification\n","init_dataset = datasets.ImageFolder(root=PATH, transform=torchvision_transform)\n","classes = init_dataset.classes\n","print(\"Classes in dataset:\", classes)\n","\n","# Define how many times you want to enlarge the dataset\n","enlarge_factor = 3\n","\n","# Create a list to hold the datasets\n","combined_datasets = [init_dataset]\n","\n","# Add the transformed dataset to the list multiple times\n","for _ in range(enlarge_factor):\n","    transformed_dataset = datasets.ImageFolder(root=PATH, transform=combined_transform)\n","    combined_datasets.append(transformed_dataset)\n","\n","# Concatenate the datasets into a single dataset\n","enlarged_dataset = ConcatDataset(combined_datasets)\n","\n","# Create a dictionary to store DataLoaders for each class\n","class_data_loaders = {}\n","num_classes = len(classes)  # Ensure num_classes matches the actual number of classes\n","\n","# Filter dataset and create DataLoaders for each class\n","for class_idx in range(num_classes):\n","    class_indices = [i for i, (_, label) in enumerate(enlarged_dataset) if label == class_idx]\n","    class_subset = Subset(enlarged_dataset, class_indices)\n","    class_data_loaders[class_idx] = DataLoader(class_subset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","print(\"Data loaders created for each class.\")\n","train_dataloader = DataLoader(init_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot some training images\n","real_batch = next(iter(class_data_loaders[1]))\n","plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","plt.title(\"Training Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T10:20:18.197236Z","iopub.status.busy":"2023-12-23T10:20:18.196934Z","iopub.status.idle":"2023-12-23T10:20:22.691128Z","shell.execute_reply":"2023-12-23T10:20:22.690335Z","shell.execute_reply.started":"2023-12-23T10:20:18.197212Z"},"trusted":true},"outputs":[],"source":["def model_init():\n","    # Model initialization\n","    model = UNet2DModel(\n","        sample_size=IMG_SIZE,  # Set to 64\n","        in_channels=3,\n","        out_channels=3,\n","        layers_per_block=2,\n","        block_out_channels=(64, 64, 128, 128, 256, 256),\n","        down_block_types=(\n","            \"DownBlock2D\",\n","            \"DownBlock2D\",\n","            \"DownBlock2D\",\n","            \"DownBlock2D\",\n","            \"AttnDownBlock2D\",\n","            \"DownBlock2D\"\n","        ),\n","        up_block_types=(\n","            \"UpBlock2D\",\n","            \"AttnUpBlock2D\",\n","            \"UpBlock2D\",\n","            \"UpBlock2D\",\n","            \"UpBlock2D\",\n","            \"UpBlock2D\"\n","        )\n","    )\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T10:25:58.633725Z","iopub.status.busy":"2023-12-23T10:25:58.632976Z","iopub.status.idle":"2023-12-23T10:25:58.640314Z","shell.execute_reply":"2023-12-23T10:25:58.639416Z","shell.execute_reply.started":"2023-12-23T10:25:58.633683Z"},"trusted":true},"outputs":[],"source":["def sample_image_generation(model, noise_scheduler, num_generate_images, random_seed, num_timesteps):\n","    pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n","    \n","    images = pipeline(\n","        batch_size=num_generate_images,\n","        generator=torch.manual_seed(random_seed),\n","        num_inference_steps=num_timesteps\n","    ).images\n","    \n","    fig = plt.figure()\n","    for i in range(1, num_generate_images + 1):\n","        fig.add_subplot(3, 3, i)\n","        plt.imshow(images[i-1])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models = []\n","model_path = 'saved_models'\n","os.makedirs(model_path, exist_ok=True)\n","torch.cuda.empty_cache()\n","\n","for class_idx in range(num_classes):#num_classes\n","   \n","    model = model_init().to(device)\n","    # Noise scheduler\n","    noise_scheduler = DDPMScheduler(num_train_timesteps=NUM_TIMESTEPS)\n","    timesteps = torch.LongTensor([50]).to(device)\n","    \n","    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","    lr_scheduler = get_cosine_schedule_with_warmup(\n","        optimizer=optimizer,\n","        num_warmup_steps=500,\n","        num_training_steps=len(class_data_loaders[class_idx]) * NUM_EPOCHS\n","    )\n","\n","    # Accelerator setup\n","    accelerator = Accelerator(\n","        mixed_precision=MIXED_PRECISION,\n","        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS\n","    )\n","    model, optimizer, class_data_loaders[class_idx], lr_scheduler = accelerator.prepare(model, optimizer, class_data_loaders[class_idx], lr_scheduler)\n","    \n","    # Training loop\n","    start = timeit.default_timer()\n","    for epoch in tqdm(range(NUM_EPOCHS), position=0, leave=True):\n","        model.train()\n","        train_running_loss = 0\n","        for idx, batch in enumerate(tqdm(class_data_loaders[class_idx], position=0, leave=True)):\n","            clean_images = batch[0].to(device)  # Assuming class_data_loaders[class_idx] returns (images, labels) tuples\n","            noise = torch.randn(clean_images.shape).to(device)\n","            last_batch_size = len(clean_images)\n","            \n","            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (last_batch_size,)).to(device)\n","            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n","            \n","            with accelerator.accumulate(model):\n","                noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n","                loss = F.mse_loss(noise_pred, noise)\n","                accelerator.backward(loss)\n","                \n","                accelerator.clip_grad_norm_(model.parameters(), 1.0)\n","                optimizer.step()\n","                lr_scheduler.step()\n","                optimizer.zero_grad()\n","                \n","            train_running_loss += loss.item()\n","        train_loss = train_running_loss / (idx + 1)\n","        \n","        train_learning_rate = lr_scheduler.get_last_lr()[0]\n","        print(\"-\" * 30)\n","        print(f\"\\rTrain Loss EPOCH: {epoch + 1}: {train_loss:.4f}\", end=\"\")\n","        print(f\"\\rTrain Learning Rate EPOCH: {epoch + 1}: {train_learning_rate}\", end=\"\")\n","        if epoch % 250 == 0:\n","            sample_image_generation(model, noise_scheduler, NUM_GENERATE_IMAGES, RANDOM_SEED, NUM_TIMESTEPS)\n","        print(\"-\" * 30)\n","\n","    stop = timeit.default_timer()\n","    print(f\"Training Time: {stop - start:.2f}s\")\n","    \n","    model_path_ = os.path.join(model_path, f\"model_DDPM_{class_idx}.pth\")\n","    torch.save(model.state_dict(), model_path_)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
