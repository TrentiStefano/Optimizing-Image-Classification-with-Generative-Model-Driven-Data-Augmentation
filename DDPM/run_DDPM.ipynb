{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline\n",
    "from accelerate import Accelerator\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "RANDOM_SEED = 42\n",
    "IMG_SIZE = 64 \n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 500\n",
    "NUM_GENERATE_IMAGES = 9\n",
    "NUM_TIMESTEPS = 1000\n",
    "MIXED_PRECISION = \"fp16\"\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "CLASSES = 10\n",
    "\n",
    "# Torch configs\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    # Model initialization\n",
    "    model = UNet2DModel(\n",
    "        sample_size=IMG_SIZE,  \n",
    "        in_channels=3,\n",
    "        out_channels=3,\n",
    "        layers_per_block=2,\n",
    "        block_out_channels=(64, 64, 128, 128, 256, 256),\n",
    "        down_block_types=(\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"AttnDownBlock2D\",\n",
    "            \"DownBlock2D\"\n",
    "        ),\n",
    "        up_block_types=(\n",
    "            \"UpBlock2D\",\n",
    "            \"AttnUpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\"\n",
    "        )\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample image generation function\n",
    "def sample_image_generation(model, noise_scheduler, num_generate_images, random_seed, num_timesteps):\n",
    "    pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
    "    images = pipeline(\n",
    "        batch_size=num_generate_images,\n",
    "        generator=torch.manual_seed(random_seed),\n",
    "        num_inference_steps=num_timesteps\n",
    "    ).images\n",
    "    fig = plt.figure()\n",
    "    for i in range(1, num_generate_images + 1):\n",
    "        fig.add_subplot(3, 3, i)\n",
    "        plt.imshow(images[i-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "models = {}\n",
    "accelerator = Accelerator(\n",
    "        mixed_precision=MIXED_PRECISION,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS\n",
    "    )\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=NUM_TIMESTEPS)\n",
    "\n",
    "for class_idx in range(CLASSES):\n",
    "    models[class_idx] = model_init().to(device)\n",
    "    model_path_ = os.path.join(model_path, f\"model_DDPM_{class_idx}.pth\")\n",
    "    models[class_idx].load_state_dict(torch.load(model_path_))\n",
    "    \n",
    "print('Loaded pre-trained models\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class_idx in range(CLASSES):\n",
    "#    sample_image_generation(models[class_idx], noise_scheduler, NUM_GENERATE_IMAGES, RANDOM_SEED, NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(models, num_images_per_class, num_classes, random_seed, num_timesteps, device, save=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    output_dir = 'generated_dataset/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    real_class_names = [12, 13, 24, 38, 39, 44, 46, 49, 50, 6]\n",
    "    all_generated_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for class_label in range(num_classes):\n",
    "        model = models[class_label].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
    "    \n",
    "            gen_images = pipeline(\n",
    "                batch_size=num_images_per_class,\n",
    "                generator=torch.manual_seed(random_seed),\n",
    "                num_inference_steps=num_timesteps\n",
    "            ).images\n",
    "    \n",
    "        for i in range(len(gen_images)):\n",
    "            \n",
    "            generated_image = gen_images[i]\n",
    "            generated_image = transforms.ToTensor()(generated_image).to(device)\n",
    "            \n",
    "            if save:\n",
    "                # Denormalize the image from [-1, 1] to [0, 1]\n",
    "                denormalized_image = (generated_image + 1) / 2\n",
    "                \n",
    "                class_path = os.path.join(output_dir, f'{real_class_names[class_label]}')\n",
    "                os.makedirs(class_path, exist_ok=True)\n",
    "                image_path = os.path.join(class_path, f'{real_class_names[class_label]}_{i}.png')\n",
    "                \n",
    "                # Save the image\n",
    "                save_image(denormalized_image, image_path)\n",
    "                    \n",
    "            all_generated_images.append(generated_image)\n",
    "            all_labels.append(class_label)\n",
    "                \n",
    "    return all_generated_images, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "save = True\n",
    "all_generated_images, all_labels = generate(models, size, CLASSES, RANDOM_SEED, NUM_TIMESTEPS, device, save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
