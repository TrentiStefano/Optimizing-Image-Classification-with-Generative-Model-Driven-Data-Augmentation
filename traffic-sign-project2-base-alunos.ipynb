{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Base Model for TP2 - Do you need more signs?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import the Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:39:04.710497Z",
     "iopub.status.busy": "2023-03-26T21:39:04.709964Z",
     "iopub.status.idle": "2023-03-26T21:39:12.549925Z",
     "shell.execute_reply": "2023-03-26T21:39:12.549171Z",
     "shell.execute_reply.started": "2023-03-26T21:39:04.710398Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image # Install Pillow -> conda install anaconda::pillow or pip install pillow\n",
    "import os\n",
    "from skimage.io import  imread, imshow # Install scikit-image -> conda install scikit-image or pip install scikit-image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Load the Image Training and Test Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **i. Get the Image Dataset Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = 'data-students/TRAIN/'\n",
    "test_dataset_path = 'data-students/TEST'\n",
    "\n",
    "#gen_dataset_path = 'GEN_DATASETS/DCGAN_50'\n",
    "#gen_dataset_path = 'GEN_DATASETS/DCGAN_100'\n",
    "#gen_dataset_path = 'GEN_DATASETS/DCGAN_500'\n",
    "\n",
    "gen_dataset_path = 'GEN_DATASETS/DDPM_50'\n",
    "#gen_dataset_path = 'GEN_DATASETS/DDPM_100'\n",
    "#gen_dataset_path = 'GEN_DATASETS/DDPM_500'\n",
    "\n",
    "#gen_dataset_path = 'GEN_DATASETS/VAE_50'\n",
    "#gen_dataset_path = 'GEN_DATASETS/VAE_100'\n",
    "#gen_dataset_path = 'GEN_DATASETS/VAE_500'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Load Image Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going for the tiny version of the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:50:27.132620Z",
     "iopub.status.busy": "2023-03-26T21:50:27.132326Z",
     "iopub.status.idle": "2023-03-26T21:50:27.136984Z",
     "shell.execute_reply": "2023-03-26T21:50:27.136018Z",
     "shell.execute_reply.started": "2023-03-26T21:50:27.132590Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 75\n",
    "IMG_HEIGHT = 75\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the training dataset. Via DataGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:51:14.671543Z",
     "iopub.status.busy": "2023-03-26T21:51:14.671218Z",
     "iopub.status.idle": "2023-03-26T21:51:27.309318Z",
     "shell.execute_reply": "2023-03-26T21:51:27.308396Z",
     "shell.execute_reply.started": "2023-03-26T21:51:14.671509Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# Define the transform\n",
    "transform = transforms.Compose([transforms.Resize((IMG_WIDTH, IMG_HEIGHT)), transforms.ToTensor()])\n",
    "\n",
    "# Load datasets\n",
    "generated_dataset = datasets.ImageFolder(root=gen_dataset_path, transform=transform)\n",
    "traffic_signals_dataset = datasets.ImageFolder(root=train_dataset_path, transform=transform)\n",
    "\n",
    "AUGMENT_DATASET = True\n",
    "\n",
    "if AUGMENT_DATASET:\n",
    "    combined_dataset = ConcatDataset([traffic_signals_dataset, generated_dataset])\n",
    "    \n",
    "    # Merge class_to_idx\n",
    "    class_to_idx_traffic = traffic_signals_dataset.class_to_idx\n",
    "    class_to_idx_generated = generated_dataset.class_to_idx\n",
    "    \n",
    "    combined_class_to_idx = class_to_idx_traffic.copy()\n",
    "    max_idx = max(combined_class_to_idx.values()) + 1\n",
    "    for key, value in class_to_idx_generated.items():\n",
    "        if key in combined_class_to_idx:\n",
    "            combined_class_to_idx[key] = max_idx\n",
    "            max_idx += 1\n",
    "        else:\n",
    "            combined_class_to_idx[key] = value + max_idx\n",
    "    \n",
    "    # Combine targets\n",
    "    combined_targets = traffic_signals_dataset.targets + [combined_class_to_idx[generated_dataset.classes[idx]] for idx in generated_dataset.targets]\n",
    "else:\n",
    "    combined_dataset = traffic_signals_dataset\n",
    "    combined_class_to_idx = traffic_signals_dataset.class_to_idx\n",
    "    combined_targets = traffic_signals_dataset.targets\n",
    "\n",
    "# Reverse the mapping to get the real labels\n",
    "labels = {value: key for key, value in combined_class_to_idx.items()}\n",
    "the_real_labels = {idx: label for label, idx in combined_class_to_idx.items()}\n",
    "\n",
    "# Perform train-test split\n",
    "train_idx, valid_idx = train_test_split(\n",
    "    range(len(combined_dataset)),\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    stratify=combined_targets\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "train_subset = Subset(combined_dataset, train_idx)\n",
    "valid_subset = Subset(combined_dataset, valid_idx)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "validation_dataset_loader = DataLoader(valid_subset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets = combined_targets\n",
    "t_targets = {k:0 for k in training_targets}\n",
    "for t in training_targets:\n",
    "    t_targets[t] += 1\n",
    "print('Training class distribution:', t_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:51:27.311341Z",
     "iopub.status.busy": "2023-03-26T21:51:27.311054Z",
     "iopub.status.idle": "2023-03-26T21:51:27.634985Z",
     "shell.execute_reply": "2023-03-26T21:51:27.633561Z",
     "shell.execute_reply.started": "2023-03-26T21:51:27.311309Z"
    }
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def get_int(self, text):\n",
    "        return [int(c) if c.isdigit() else c for c in re.split('(\\d+)', text)]\n",
    "    \n",
    "    def __init__(self, images_folder, transform=None):\n",
    "        self.images_folder = images_folder\n",
    "        self.image_files = [f for f in os.listdir(images_folder) if os.path.isfile(os.path.join(images_folder, f))]\n",
    "        self.image_files.sort(key=self.get_int)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_folder, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "inference_dataset = TestDataset(images_folder=test_dataset_path, transform=transform)\n",
    "\n",
    "test_dataset_loader = DataLoader(inference_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **iii. Get the Label Mappings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels dictionary is made in order to retrive the class names against the label indices used for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:51:39.679438Z",
     "iopub.status.busy": "2023-03-26T21:51:39.679162Z",
     "iopub.status.idle": "2023-03-26T21:51:39.686686Z",
     "shell.execute_reply": "2023-03-26T21:51:39.685704Z",
     "shell.execute_reply.started": "2023-03-26T21:51:39.679410Z"
    }
   },
   "outputs": [],
   "source": [
    "### subset version\n",
    "#the_labels = {value for _, value in train_datagen.class_to_idx.items()}\n",
    "labels = {value: key for key, value in combined_class_to_idx.items()}\n",
    "print(labels)\n",
    "the_real_labels = {}\n",
    "with open(\"data-students/labels.csv\",\"r\") as label_f:\n",
    "    for line in label_f.readlines()[1:]:\n",
    "        label_value, label_description = line.strip().split(\";\")\n",
    "        the_real_labels[int(label_value)] = label_description \n",
    "\n",
    "print(the_real_labels)\n",
    "\n",
    "print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
    "for key, value in labels.items():\n",
    "    print(f\"{key} : {value} - {the_real_labels[int(value)]}\")\n",
    "the_labels_map = {key: value for key, value in combined_class_to_idx.items()}\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, img_width, img_height, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=128, kernel_size=5, padding='valid')\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=128)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding='valid', bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding='valid', bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(32 * self._conv_output_shape(img_width, img_height), 256)  # Assuming square input for simplification\n",
    "        self.fc1 = nn.Linear(1568,256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # L2 regularization is not directly included in layers in PyTorch, \n",
    "        # it's typically added to the optimizer during the training step.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _conv_output_shape(self, img_width, img_height, kernel_size=3, stride=1, padding=0, dilation=1):\n",
    "        h = ((img_height + (2 * padding) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "        w = ((img_width + (2 * padding) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "        return int(h/8) * int(w/8)  # Considering three max pooling layers with kernel_size=2, stride=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_dataset_loader, num_epochs=10, device='cpu'):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        cumulative_loss = 0\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_dataset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = output.max(1)\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Step {batch_idx+1}/{len(train_dataset_loader)}, Loss: {loss.item():.4f}')\n",
    "            cumulative_loss += loss.item()\n",
    "\n",
    "        # Calculate balanced accuracy for the epoch\n",
    "        balanced_acc = balanced_accuracy_score(all_targets, all_predictions)\n",
    "        print(f\"Epoch {epoch+1} average loss: {cumulative_loss/len(train_dataset_loader):.4f}\")\n",
    "        print(f\"Epoch {epoch+1} balanced accuracy: {balanced_acc:.4f}\")\n",
    "\n",
    "    return model.to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "num_classes = len(labels)\n",
    "print(num_classes)\n",
    "print(device)\n",
    "num_epochs = 15\n",
    "model = CustomCNN(IMG_WIDTH, IMG_HEIGHT, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODEL = True\n",
    "\n",
    "\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    ccnn = train_model(model, criterion, optimizer, train_dataset_loader, num_epochs, device)\n",
    "    \n",
    "else:\n",
    "    ccnn = torch.load('baseline_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_model(model, dataset_loader, device='cpu'):\n",
    "    y_real = []\n",
    "    y_pred = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in dataset_loader:\n",
    "            y_real.extend(labels.numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    balanced_acc = balanced_accuracy_score(y_real, y_pred)\n",
    "    print(f'Accuracy of the model on the {total} test images: {accuracy:.2f} %')\n",
    "    print(f'Balanced accuracy of the model on the {total} test images: {balanced_acc:.4f}')\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_model(ccnn, validation_dataset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_str_id = [\n",
    "    \"12\",\n",
    "    \"13\",\n",
    "    \"24\",\n",
    "    \"38\",\n",
    "    \"39\",\n",
    "    \"44\",\n",
    "    \"46\",\n",
    "    \"49\",\n",
    "    \"50\",\n",
    "    \"6\"\n",
    "]\n",
    "\n",
    "import csv\n",
    "\n",
    "def createCSV(model, test_dataset_loader, name, device='cpu'):\n",
    "    # Move model to the appropriate device\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Determine the directory to save the CSV file\n",
    "    try:\n",
    "        import google.colab\n",
    "        IN_COLAB = True\n",
    "    except ImportError:\n",
    "        IN_COLAB = False\n",
    "\n",
    "    if IN_COLAB:\n",
    "        save_dir = \"/content/drive/MyDrive/Project1-AML/Nic/\"\n",
    "    else:\n",
    "        save_dir = \"/home/stefanotrenti/AML/project2/TP2/CSVs\"\n",
    "\n",
    "    # Define the file name and path\n",
    "    csv_file = os.path.join(save_dir, name)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, images in enumerate(test_dataset_loader):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            test_predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Move predictions back to the CPU\n",
    "            predicted_classes = test_predictions.cpu().numpy()\n",
    "\n",
    "            # Iterate over the batch\n",
    "            predicted_class = int(predicted_classes[0])  # Extract the integer value\n",
    "            data.append({\"ID\": i + 1, \"Class\": label_str_id[predicted_class]})\n",
    "\n",
    "    # Define the field names\n",
    "    fields = [\"ID\", \"Class\"]\n",
    "\n",
    "    # Write data to CSV file\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fields)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write the data rows\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(\"CSV file created successfully.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createCSV(ccnn, test_dataset_loader,\"ccnn_baseline_with_training.csv\")\n",
    "\n",
    "#createCSV(ccnn, test_dataset_loader,\"VAE_50.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"VAE_100.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"VAE_500.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"DCGAN_50.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"DCGAN_100.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"DCGAN_500.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"DDPM_50.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"DDPM_100.csv\")\n",
    "#createCSV(ccnn, test_dataset_loader,\"DDPM_500.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
